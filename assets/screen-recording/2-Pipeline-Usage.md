# headline: ä½¿ç”¨ pipeline è¿›è¡Œæ¨ç†


```python
from transformers import pipeline

transcriber = pipeline(task="automatic-speech-recognition")
```

    No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).
    Using a pipeline without specifying a model name and revision in production is not recommended.
    
    ...
    
    Feature extractor Wav2Vec2FeatureExtractor {
      "do_normalize": true,
      "feature_extractor_type": "Wav2Vec2FeatureExtractor",
      "feature_size": 1,
      "padding_side": "right",
      "padding_value": 0.0,
      "return_attention_mask": false,
      "sampling_rate": 16000
    }
    
    


```python
transcriber(
    "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
```

    ---------------------------------------------------------------------------

    FileNotFoundError                         Traceback (most recent call last)

    ...

    ValueError: ffmpeg was not found but is required to load audio files from filename


# å‚æ•°

> pipeline æ”¯æŒè®¸å¤šå‚æ•°ï¼Œæœ‰äº›é€‚ç”¨äºç‰¹å®šä»»åŠ¡ï¼Œæœ‰äº›é€‚ç”¨äºæ‰€æœ‰ pipelineã€‚é€šå¸¸åœ¨ä»»ä½•åœ°æ–¹éƒ½å¯ä»¥æŒ‡å®šå¯¹åº”å‚æ•°


```python
transcriber = pipeline(model="openai/whisper-large-v2", my_parameter=1)
```

    loading configuration file config.json from cache at F:\Huggingface_cache\models--openai--whisper-large-v2\snapshots\ae4642769ce2ad8fc292556ccea8e901f1530655\config.json

      ...

    TypeError: AutomaticSpeechRecognitionPipeline._sanitize_parameters() got an unexpected keyword argument 'my_parameter'


# åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨ pipeline


```python
# å®šä¹‰ä¸€ä¸ªè¿­ä»£å™¨å‡½æ•°
def data():
    for i in range(10):
        yield f"My example {i}"


# ç”¨ pipeline ä¸‹è½½å¹¶ç”Ÿæˆä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹
pipe = pipeline(model='openai-community/gpt2', device=0)

generated_characters = 0

# è‡ªåŠ¨è¯†åˆ«è¾“å…¥ä¸ºå¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨ GPU ä¸Šå¤„ç†æ•°æ®çš„åŒæ—¶å¼€å§‹è·å–æ•°æ®ï¼ˆåœ¨åº•å±‚ä½¿ç”¨ DataLoaderï¼‰
for out in pipe(data()):
    generated_characters += len(out[0]['generated_text'])

generated_characters
```

    Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.

    ...

    1940




```python
pipe('My example 1')
```

    [{'generated_text': 'My example 1 will start with a simple graph, see the diagram here:\n\nNote as well of course that this function is called from any sort of thread. So, it does not actually send the data, but to a single thread to send'}]

> è¿­ä»£æ•°æ®é›†æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä» Datasets ä¸ŠåŠ è½½æ•°æ®é›†


```python
from transformers.pipelines.pt_utils import KeyDataset
from transformers import pipeline
from datasets import load_dataset

pipe = pipeline(model='hf-internal-testing/tiny-random-wav2vec2', device=0)

dataset = load_dataset('hf-internal-testing/librispeech_asr_dummy',
                       'clean',
                       split='validation[:10]')

for out in pipe(KeyDataset(dataset=dataset, key='audio')):
    print(out)
```

    {'text': "EYB  ZB COE C BEZCYCZ HO MOWWB EM BWOB ZMEG  B COEB BE BEC B U OB BE BCB BEWUBB 
    ...
    
    BUCWSE EZ MZOSOECO ZY ZY SZB  B SBT T SB  XEGBMCBE B BEB BE B EBEB  ZE BEH  B B W EC USB E B 'B"}
    

# è§†è§‰æµæ°´çº¿

> å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œä½¿ç”¨ pipeline() å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚æŒ‡å®šä»»åŠ¡å¹¶å°†å›¾åƒä¼ é€’ç»™åˆ†ç±»å™¨ï¼Œå›¾åƒå¯ä»¥æ˜¯é“¾æ¥ã€æœ¬åœ°è·¯å¾„æˆ–è€… base64 ç¼–ç çš„å›¾åƒã€‚

![](./pipeline-cat-chonk.jpeg)


```python
from transformers import pipeline

vision_classifier = pipeline(model="google/vit-base-patch16-224")

preds = vision_classifier(images="./pipeline-cat-chonk.jpeg")

preds = [{
    "score": round(pred["score"], 4),
    "label": pred["label"]
} for pred in preds]

preds
```

    [{'score': 0.4403, 'label': 'lynx, catamount'},
     {'score': 0.0343,
      'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},
     {'score': 0.0321, 'label': 'snow leopard, ounce, Panthera uncia'},
     {'score': 0.0235, 'label': 'Egyptian cat'},
     {'score': 0.023, 'label': 'tiger cat'}]



# æ–‡æœ¬æµæ°´çº¿

> å¯¹äº NLPï¼ˆè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰ä»»åŠ¡ï¼Œä½¿ç”¨ pipeline() å‡ ä¹æ˜¯ç›¸åŒçš„


```python
from transformers import pipeline

# This model is a `zero-shot-classification` model.
# It will classify text, except you are free to choose any label you might imagine
# å¤„ç†é›¶æ–‡æœ¬è¾“å…¥çš„åˆ†ç±»é—®é¢˜
classifier = pipeline('zero-shot-classification',
                      model='facebook/bart-large-mnli')

text = 'I have a problem with my iphone that needs to be resolved asap!!'

classifier(
    text,
    # urgent ç´§æ€¥çš„ï¼Œtablet å¹³æ¿
    candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"])
```

    {'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',
     'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],
     'scores': [0.5036357045173645,
      0.47879961133003235,
      0.012600073590874672,
      0.0026557939127087593,
      0.002308752853423357]}


# å¤šæ¨¡æ€æµæ°´çº¿

> pipeline æ”¯æŒå¤šä¸ªæ¨¡æ€ã€‚ä¾‹å¦‚ï¼Œè§†è§‰é—®é¢˜é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒã€‚

> æå‰å®‰è£… pytesseract

```
pip install pytesseract
```

> æœ¬åœ°å®‰è£… tesseract-ocr

> ä»é¡µé¢ https://github.com/UB-Mannheim/tesseract/wiki ä¸‹è½½åŸºäº Windows çš„ tesseract-ocr çš„ exe å®‰è£…æ–‡ä»¶ã€‚å½“å‰å®‰è£…çš„è·¯å¾„ä¸º D:\Program Files\Tesseract-OCRï¼Œç„¶åæŠŠè¿™ä¸ªè·¯å¾„ D:\Program Files\Tesseract-OCR é…ç½®åˆ°ç¯å¢ƒå˜é‡ä¸­ã€‚ç»§ç»­å°†ä¸‹é¢çš„åŒ…å®‰è£…å®Œæˆåï¼Œé‡å¯ç¬”è®°æœ¬ï¼Œè¿è¡Œä¸‹é¢çš„ç¨‹åºå°±ä¸ä¼šå‡ºç°é”™è¯¯æç¤ºã€‚

![](tesseract-ocr-installation.png)

> å®‰è£… tesseract

```
pip install tesseract
```

> Python-tesseract is an optical character recognition (OCR) tool for python. That is, it will recognize and â€œreadâ€ the text embedded in images.

![](./invoice.png)


```python
from transformers import pipeline

vqa = pipeline(task='document-question-answering',
               model='impira/layoutlm-document-qa')

vqa(image='./invoice.png', question='What is the invoice number?')
```




    [{'score': 0.9998127222061157, 'answer': 'us-001', 'start': 15, 'end': 15}]



> ä»è¾“å‡ºçš„ç»“æœçœ‹åˆ°ï¼Œæ¨¡å‹æ ¹æ®é—®é¢˜ï¼ˆquestionï¼‰ï¼Œä»å›¾ç‰‡é‡Œè¯†åˆ«å‡ºäº†é—®é¢˜çš„ç­”æ¡ˆ us-001ï¼Œå°±æ˜¯å›¾ç‰‡å³ä¸Šæ–¹çš„å†…å®¹ã€‚

# åœ¨å¤§æ¨¡å‹ä¸Šä½¿ç”¨ğŸ¤— accelerate å’Œ pipeline


```python
import torch
from transformers import pipeline

pipe = pipeline(model='facebook/opt-1.3b',torch_dtype=torch.bfloat16,device_map='auto')

output = pipe('This is a cool example', do_sample=True, top_p=0.95)

output
```

    [{'generated_text': 'This is a cool example of the use of 2x2 and 4x4 for a box/'}]


# Thanks